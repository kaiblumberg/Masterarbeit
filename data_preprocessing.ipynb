{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the dataframe from the raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import spacy\n",
    "import re\n",
    "from lingua import Language, LanguageDetectorBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    global empty_counter\n",
    "\n",
    "    # Load the XML file\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Define the namespace\n",
    "    namespace = {\n",
    "        'atom': 'http://www.w3.org/2005/Atom',\n",
    "        'nitf': 'http://iptc.org/std/NITF/2006-10-18/',\n",
    "        'dc': 'http://purl.org/dc/elements/1.1/'\n",
    "    }\n",
    "\n",
    "    # Extract the ID\n",
    "    nexis_id = root.find('.//atom:id', namespace).text\n",
    "    nexis_id = nexis_id.split('Item:')[1]\n",
    "    nexis_id = nexis_id.replace(\"-\", \"\")\n",
    "\n",
    "    # Extract the title\n",
    "    title = root.find('.//atom:title', namespace).text\n",
    "\n",
    "    # Extract the published date\n",
    "    published_date = root.find('.//atom:published', namespace).text\n",
    "    published_date = published_date.split('T')[0]\n",
    "\n",
    "    # Extract the publisher\n",
    "    publisher = root.find('.//metadata/publicationInfo/publicationName').text\n",
    "\n",
    "\n",
    "    # Extract the body text\n",
    "    body_text = root.find('.//nitf:body.content//bodyText//p', namespace)\n",
    "\n",
    "    # Extract all body paragraphs and join them into a single line\n",
    "    body_paragraphs = []\n",
    "    body_text_element = root.find('.//nitf:body.content//bodyText', namespace)\n",
    "    if body_text_element is not None:\n",
    "        for p_element in body_text_element.findall('.//p', namespace):\n",
    "            if p_element.text:\n",
    "                body_paragraphs.append(p_element.text.strip())\n",
    "    text = ' '.join(body_paragraphs)\n",
    "\n",
    "    # Check for empty text bodies and return\n",
    "    if text == '':\n",
    "        #print('No text body in file ' + file_path)\n",
    "        empty_counter += 1\n",
    "        return\n",
    "\n",
    "    # Create a dictionary with the extracted values\n",
    "    data_dict = {\n",
    "        'nexis_id': [nexis_id],\n",
    "        'title': [title],\n",
    "        'publication_date': [published_date],\n",
    "        'publisher': [publisher],\n",
    "        'text': [text]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in file c:\\Friendcloud\\_University\\_Masterarbeit\\Data\\Nexis\\DieZEITinklusiveZEITMagazin\\533RXXJ1JDPTM3D40000000_Die_neuen_Weltwunder_Acht_technische.xml\n"
     ]
    }
   ],
   "source": [
    "# Root Directory of the data\n",
    "folder_path = 'c:\\\\Friendcloud\\\\_University\\\\_Masterarbeit\\\\Data\\\\Nexis\\\\'\n",
    "\n",
    "# Initialize empty counter\n",
    "empty_counter = 0\n",
    "\n",
    "# Go through all subdirectories and fill raw_data with the data\n",
    "raw_data = []\n",
    "for root, _, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.xml'):\n",
    "            try:\n",
    "                file_path = os.path.join(root, file)\n",
    "                data = parse_xml(file_path)\n",
    "                raw_data.append(data)\n",
    "            except:\n",
    "                print('Error in file ' + file_path)\n",
    "\n",
    "# Build pandas DataFrame\n",
    "df_raw = pd.concat(raw_data, ignore_index=True)\n",
    "print('Number of articles removed: ' + str(empty_counter))\n",
    "print('Number of articles accepted: ' + str(len(df_raw.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_pickle(\"../Data/df_raw.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.read_pickle(\"../Data/df_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year of publication to dataset\n",
    "df_processed['publication_date'] = pd.to_datetime(df_processed['publication_date'], errors='coerce')\n",
    "df_processed['publication_year'] = df_processed['publication_date'].dt.year\n",
    "df_processed = df_processed[['nexis_id', 'title', 'publication_date', 'publication_year', 'publisher', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles removed: 3\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with duplicate id\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed.drop_duplicates(subset='nexis_id', keep='first')\n",
    "count_after = len(df_processed.index)\n",
    "print('Number of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>5GFW20B1JDMNJ04J0000000</td>\n",
       "      <td>Freihandelsabkommen: \"Aufklärung tut Not\"</td>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>2015</td>\n",
       "      <td>Lampertheimer Zeitung (Germany)</td>\n",
       "      <td>bergstrasse (red). Das Risiko TTIP bleibt, auc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>3WY2885000DBC32X0000000</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-08-10</td>\n",
       "      <td>2023</td>\n",
       "      <td>Lebensmittel Zeitung</td>\n",
       "      <td>Frankfurt, 12. Mai. Die grossen Markenartikel-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>6787MRT1DYHXW5160000000</td>\n",
       "      <td>Fleisch aus dem Labor bald im Regal</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>2023</td>\n",
       "      <td>Neuss Grevenbroicher Zeitung</td>\n",
       "      <td>Reinhard Kowalewsky Düsseldorf Müssen die Fest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>5VJGKC11F16N039M0000000</td>\n",
       "      <td>Sprachregelungen</td>\n",
       "      <td>2019-03-02</td>\n",
       "      <td>2019</td>\n",
       "      <td>WELT ONLINE (Deutsch)</td>\n",
       "      <td>Es gibt Gesetze, deren Name ist eine Zumutung....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>5VRYTP21F13R82VM0000000</td>\n",
       "      <td>Da ist der Wurm drin</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>2019</td>\n",
       "      <td>Main-Spitze (Germany)</td>\n",
       "      <td>Darmstadt. Das Salatblatt knackt. Der Saft der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>6317YD91JC4YS4YD0000000</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tages-Anzeiger</td>\n",
       "      <td>Was ist Clean Meat? Was Paul Shapiro als «Clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>64D2FWD1JBN971940000000</td>\n",
       "      <td>Veganes Fleisch boomt -auch dank Planted</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>2021</td>\n",
       "      <td>Neue Zürcher Zeitung (Internationale Ausgabe) ...</td>\n",
       "      <td>Rewert Hoffer Pascal Bieri verspätet sich. Der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>6787MRJ1DYHXW3FY0000000</td>\n",
       "      <td>Fleisch aus dem Labor bald im Regal</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>2023</td>\n",
       "      <td>Solinger Morgenpost</td>\n",
       "      <td>Reinhard Kowalewsky Düsseldorf Müssen die Fest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>68R61GC1JCNGC4DV0000000</td>\n",
       "      <td>Für unsere Lieblinge: Da ist Fliege drin</td>\n",
       "      <td>2023-07-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nordwest-Zeitung</td>\n",
       "      <td>Und damit hat sich alles reguliert.  Seit über...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>5XCNKHM1JDRK82WY0000000</td>\n",
       "      <td>Schmetterlinge im Bauch</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>2019</td>\n",
       "      <td>WELT ONLINE (Deutsch)</td>\n",
       "      <td>Okidoki. Das war ja eigentlich klar. Früher od...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id                                      title   \n",
       "2944  5GFW20B1JDMNJ04J0000000  Freihandelsabkommen: \"Aufklärung tut Not\"  \\\n",
       "3142  3WY2885000DBC32X0000000                                       None   \n",
       "4012  6787MRT1DYHXW5160000000        Fleisch aus dem Labor bald im Regal   \n",
       "6507  5VJGKC11F16N039M0000000                           Sprachregelungen   \n",
       "3611  5VRYTP21F13R82VM0000000                       Da ist der Wurm drin   \n",
       "5539  6317YD91JC4YS4YD0000000                                       None   \n",
       "3959  64D2FWD1JBN971940000000   Veganes Fleisch boomt -auch dank Planted   \n",
       "4784  6787MRJ1DYHXW3FY0000000        Fleisch aus dem Labor bald im Regal   \n",
       "4110  68R61GC1JCNGC4DV0000000   Für unsere Lieblinge: Da ist Fliege drin   \n",
       "6537  5XCNKHM1JDRK82WY0000000                    Schmetterlinge im Bauch   \n",
       "\n",
       "     publication_date  publication_year   \n",
       "2944       2015-07-17              2015  \\\n",
       "3142       2023-08-10              2023   \n",
       "4012       2023-01-07              2023   \n",
       "6507       2019-03-02              2019   \n",
       "3611       2019-03-29              2019   \n",
       "5539       2021-06-27              2021   \n",
       "3959       2021-12-27              2021   \n",
       "4784       2023-01-07              2023   \n",
       "4110       2023-07-18              2023   \n",
       "6537       2019-10-29              2019   \n",
       "\n",
       "                                              publisher   \n",
       "2944                    Lampertheimer Zeitung (Germany)  \\\n",
       "3142                               Lebensmittel Zeitung   \n",
       "4012                       Neuss Grevenbroicher Zeitung   \n",
       "6507                              WELT ONLINE (Deutsch)   \n",
       "3611                              Main-Spitze (Germany)   \n",
       "5539                                     Tages-Anzeiger   \n",
       "3959  Neue Zürcher Zeitung (Internationale Ausgabe) ...   \n",
       "4784                                Solinger Morgenpost   \n",
       "4110                                   Nordwest-Zeitung   \n",
       "6537                              WELT ONLINE (Deutsch)   \n",
       "\n",
       "                                                   text  \n",
       "2944  bergstrasse (red). Das Risiko TTIP bleibt, auc...  \n",
       "3142  Frankfurt, 12. Mai. Die grossen Markenartikel-...  \n",
       "4012  Reinhard Kowalewsky Düsseldorf Müssen die Fest...  \n",
       "6507  Es gibt Gesetze, deren Name ist eine Zumutung....  \n",
       "3611  Darmstadt. Das Salatblatt knackt. Der Saft der...  \n",
       "5539  Was ist Clean Meat? Was Paul Shapiro als «Clea...  \n",
       "3959  Rewert Hoffer Pascal Bieri verspätet sich. Der...  \n",
       "4784  Reinhard Kowalewsky Düsseldorf Müssen die Fest...  \n",
       "4110  Und damit hat sich alles reguliert.  Seit über...  \n",
       "6537  Okidoki. Das war ja eigentlich klar. Früher od...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find examples of articles with duplicate text\n",
    "df_processed[df_processed.duplicated(subset='text', keep=False)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles removed: 1278\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with duplicate text\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed.drop_duplicates(subset='text', keep='first')\n",
    "count_after = len(df_processed.index)\n",
    "print('Number of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles removed: 73\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with length less than 100 characters\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['text'].str.len() > 100]\n",
    "count_after = len(df_processed.index)\n",
    "print('Number of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "EN    118\n",
      "ES      1\n",
      "Name: count, dtype: int64\n",
      "publisher\n",
      "dpa-AFX ProFeed                                                              19\n",
      "News Bites - People in Business                                              12\n",
      "American Banking and Market News                                             10\n",
      "Spiegel Online                                                                7\n",
      "Industry SnapShot                                                             4\n",
      "GJAE - German Journal of Agricultural Economics (ehemals Agrarwirtschaft)     4\n",
      "Agrarwirtschaft                                                               4\n",
      "Newstex Blogs                                                                 4\n",
      "Industry SnapShot Summary                                                     3\n",
      "PR Newswire                                                                   2\n",
      "MENAFN - Market Reports (English)                                             2\n",
      "MENAFN - Press Releases (English)                                             2\n",
      "Dorset Echo                                                                   1\n",
      "The Sunday Times (London)                                                     1\n",
      "TVEyes - BBC 1 Yorkshire and Lincolnshire                                     1\n",
      "TVEyes - BBC 1 South East                                                     1\n",
      "TVEyes - BBC 1 Southampton                                                    1\n",
      "TVEyes - BBC 1 North West                                                     1\n",
      "TVEyes - BBC 1 Wales                                                          1\n",
      "TVEyes - BBC 1 Scotland                                                       1\n",
      "The Philadelphia Daily News                                                   1\n",
      "Medical Buyer                                                                 1\n",
      "Seeking Alpha - Earnings Call Transcripts                                     1\n",
      "Oxford Mail                                                                   1\n",
      "TVEyes - BBC 1 East Midlands                                                  1\n",
      "The Philadelphia Inquirer                                                     1\n",
      "Die Welt                                                                      1\n",
      "dailyrecord.co.uk                                                             1\n",
      "Brisbane Times                                                                1\n",
      "just-food global news                                                         1\n",
      "Process                                                                       1\n",
      "Bournemouth Echo                                                              1\n",
      "SPIEGEL ONLINE                                                                1\n",
      "TVEyes - BBC 1 East                                                           1\n",
      "TVEyes - BBC 1 Northern Ireland                                               1\n",
      "Xinhua General News Service                                                   1\n",
      "FD (Fair Disclosure) Wire                                                     1\n",
      "The Times of Israel                                                           1\n",
      "FoodNavigator-Asia.com                                                        1\n",
      "UNI (United News of India)                                                    1\n",
      "The Guardian (London)                                                         1\n",
      "TVEyes - BBC Radio 4                                                          1\n",
      "The Northern Echo (Newsquest Regional Press)                                  1\n",
      "thetimes.co.uk                                                                1\n",
      "Hispanic PR Wire English                                                      1\n",
      "Global Data Point                                                             1\n",
      "Communications Earth & Environment                                            1\n",
      "Targeted News Service                                                         1\n",
      "Market News Publishing                                                        1\n",
      "Sydney Morning Herald (Australia)                                             1\n",
      "The Shelby Report                                                             1\n",
      "PR Newswire Asia                                                              1\n",
      "Business Monitor Online                                                       1\n",
      "Hispanic PR Wire Spanish                                                      1\n",
      "manchestereveningnews.co.uk                                                   1\n",
      "WELT ONLINE (Deutsch)                                                         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of articles removed: 119\n"
     ]
    }
   ],
   "source": [
    "# Remove articles which are not in German using lingua\n",
    "detector = LanguageDetectorBuilder.from_all_spoken_languages().build()\n",
    "\n",
    "# Add empty language column to dataset\n",
    "df_processed['language'] = ''\n",
    "\n",
    "# Detect language of each article\n",
    "for index, row in df_processed.iterrows():\n",
    "    text = row['text']\n",
    "    language = detector.detect_language_of(text)\n",
    "    df_processed.at[index, 'language'] = language.iso_code_639_1.name\n",
    "\n",
    "# Print the language and publisher of articles which are not in German\n",
    "print(df_processed[df_processed['language'] != 'DE']['language'].value_counts())\n",
    "print(df_processed[df_processed['language'] != 'DE']['publisher'].value_counts())\n",
    "\n",
    "# Remove articles which are not in German\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['language'] == 'DE']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of articles removed: 4\n",
      "\n",
      "Number of articles removed: 1\n",
      "\n",
      "Number of articles removed: 2\n",
      "\n",
      "Number of articles removed: 3\n",
      "\n",
      "Number of articles removed: 10\n",
      "\n",
      "Number of articles removed: 2\n",
      "\n",
      "Number of articles removed: 6\n",
      "\n",
      "Number of articles removed: 30\n",
      "\n",
      "Number of articles removed: 1\n",
      "\n",
      "Number of articles removed: 1\n",
      "\n",
      "Number of articles removed: 9\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with title 'Programmübersicht'\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['title'] != 'Programmübersicht']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with title 'Programmübersicht Samstag'\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['title'] != 'Programmübersicht Samstag']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with title 'Programmhinweise'\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['title'] != 'Programmhinweise']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with specific nexis_ids (tv program)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4SC3XK90TXHH10SS0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4SC3XKC0TXHH101J0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4SC3XKJ0TXHH101K0000000']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with specific nexis_ids (theatre)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4JXWDKF0TWRXK1R10000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '3SGDYHS0006XC4P80000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '5KNN3CD1JC3P04FD0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4KF5FDD0TWRXK1WY0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '585XW971JBPW93GX0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4S4Y46D0TWX2707B0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '554MD281F19FX2YB0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4S554KS0TWX271450000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '518R7XC1F19FX3P10000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '539ND9G1DYK6Y0950000000']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove all articles that have the word \"Dissertationen\" in the title (list of dissertations, not an article)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[~df_processed['title'].str.contains('Dissertationen', na=False)]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove all articles that have the word \"Börsentag\" in the title (not an article)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[~df_processed['title'].str.contains('Börsentag', na=False)]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove all articles that have the word \"Börsen-Ticker\" in the title (not an article)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[~df_processed['title'].str.contains('Börsen-Ticker', na=False)]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with specific nexis_ids (no article)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '65S924K1JBR841DW0000000']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with specific nexis_ids (hidden duplicate)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '64HSHSG1F15WB1NC0000000']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with publication_year before 1994 (too little data)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['publication_year'] >= 1994]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the dataframe\n",
    "df_processed = df_processed.reset_index(drop=True)\n",
    "\n",
    "# Remove the language column\n",
    "df_processed = df_processed.drop(columns=['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of articles removed: 379\n"
     ]
    }
   ],
   "source": [
    "count_before = len(df_processed.index)\n",
    "drop_ids = []\n",
    "\n",
    "# Remove all articles that have the same first 100 characters (hidden duplicates)\n",
    "for i in range(len(df_processed)):\n",
    "    for j in range(i+1, len(df_processed)):\n",
    "        text1 = df_processed['text'][i]\n",
    "        text2 = df_processed['text'][j]\n",
    "        if len(text1) >= 100 and len(text2) >= 100:\n",
    "            if text1[:100] == text2[:100]:\n",
    "                # Check whether the articles have the same nexis_id\n",
    "                if df_processed['nexis_id'][i] != df_processed['nexis_id'][j]:\n",
    "                    # Remove the shorter article\n",
    "                    if len(text1) <= len(text2):\n",
    "                        drop_ids.append(df_processed['nexis_id'][i])\n",
    "                    else:\n",
    "                        drop_ids.append(df_processed['nexis_id'][j])\n",
    "\n",
    "# Remove articles with nexis_ids in drop_ids\n",
    "for nexis_id in drop_ids:\n",
    "    df_processed = df_processed[df_processed['nexis_id'] != nexis_id]\n",
    "\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# reindex dataframe\n",
    "df_processed.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5MNMH621JB0GF09H0000000</td>\n",
       "      <td>Angst vor dem «harten Brexit» auf der Insel - ...</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Wenn Großbritannien Ende März den Ausstieg aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SM3THB1DXFJ50MP0000000</td>\n",
       "      <td>Fleischindustrie wehrt sich gegen Marketing fü...</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Fleisch aus dem Labor ist noch eine Zukunftsvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5SM3THB1DXFJ50MY0000000</td>\n",
       "      <td>Der AP-Überblick am Nachmittag</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die AP Weltnachrichten haben heute unter ander...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5STNVWH1DXFJ53VM0000000</td>\n",
       "      <td>Laborfleisch soll in drei Jahren auf die Telle...</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Maastricht (AP) - Das niederländische Unterneh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VHK2XG1JB0GF4Y50000000</td>\n",
       "      <td>Israelische Forscher wollen künstliche Steaks ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die Weltbevölkerung wächst, die Nachfrage nach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>67KW1VK1F15WB4660000000</td>\n",
       "      <td>Kein Titel</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>6 Am anfang drei Fragen 1. Können wir andere m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>67KW1VK1F15WB46B0000000</td>\n",
       "      <td>Leben und schmecken lassen</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Ein saftiges Filet, für das kein Huhn sterben ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>7W29GN20YC2460S30000000</td>\n",
       "      <td>ABSCHIED VOM ALTEN ITALIEN</td>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>John Dickie: »Delizia! Die Italiener und  ihre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>7X8DW4712SK2G0H10000000</td>\n",
       "      <td>Essen aus dem Labor</td>\n",
       "      <td>2009-12-08</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Es ist der letzte Tag auf der Lebensmittelmess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>7Y5T7F412SK2G46M0000000</td>\n",
       "      <td>15 Ideen, die unser Leben verändern ZEIT</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>2010</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Der frühere IBM-Chef Thomas Watson ist heute b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4858 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "0     5MNMH621JB0GF09H0000000  \\\n",
       "1     5SM3THB1DXFJ50MP0000000   \n",
       "2     5SM3THB1DXFJ50MY0000000   \n",
       "3     5STNVWH1DXFJ53VM0000000   \n",
       "4     5VHK2XG1JB0GF4Y50000000   \n",
       "...                       ...   \n",
       "4853  67KW1VK1F15WB4660000000   \n",
       "4854  67KW1VK1F15WB46B0000000   \n",
       "4855  7W29GN20YC2460S30000000   \n",
       "4856  7X8DW4712SK2G0H10000000   \n",
       "4857  7Y5T7F412SK2G46M0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "0     Angst vor dem «harten Brexit» auf der Insel - ...       2017-01-15  \\\n",
       "1     Fleischindustrie wehrt sich gegen Marketing fü...       2018-06-21   \n",
       "2                        Der AP-Überblick am Nachmittag       2018-06-21   \n",
       "3     Laborfleisch soll in drei Jahren auf die Telle...       2018-07-17   \n",
       "4     Israelische Forscher wollen künstliche Steaks ...       2019-02-26   \n",
       "...                                                 ...              ...   \n",
       "4853                                         Kein Titel       2023-02-21   \n",
       "4854                         Leben und schmecken lassen       2023-02-21   \n",
       "4855                         ABSCHIED VOM ALTEN ITALIEN       2009-05-13   \n",
       "4856                                Essen aus dem Labor       2009-12-08   \n",
       "4857           15 Ideen, die unser Leben verändern ZEIT       2010-04-06   \n",
       "\n",
       "      publication_year    publisher   \n",
       "0                 2017   AP Deutsch  \\\n",
       "1                 2018   AP Deutsch   \n",
       "2                 2018   AP Deutsch   \n",
       "3                 2018   AP Deutsch   \n",
       "4                 2019   AP Deutsch   \n",
       "...                ...          ...   \n",
       "4853              2023  ZEIT Wissen   \n",
       "4854              2023  ZEIT Wissen   \n",
       "4855              2009  ZEIT Wissen   \n",
       "4856              2009  ZEIT Wissen   \n",
       "4857              2010  ZEIT Wissen   \n",
       "\n",
       "                                                   text  \n",
       "0     Wenn Großbritannien Ende März den Ausstieg aus...  \n",
       "1     Fleisch aus dem Labor ist noch eine Zukunftsvi...  \n",
       "2     Die AP Weltnachrichten haben heute unter ander...  \n",
       "3     Maastricht (AP) - Das niederländische Unterneh...  \n",
       "4     Die Weltbevölkerung wächst, die Nachfrage nach...  \n",
       "...                                                 ...  \n",
       "4853  6 Am anfang drei Fragen 1. Können wir andere m...  \n",
       "4854  Ein saftiges Filet, für das kein Huhn sterben ...  \n",
       "4855  John Dickie: »Delizia! Die Italiener und  ihre...  \n",
       "4856  Es ist der letzte Tag auf der Lebensmittelmess...  \n",
       "4857  Der frühere IBM-Chef Thomas Watson ist heute b...  \n",
       "\n",
       "[4858 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_pickle(\"../Data/df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANT = \"LARGE\" # \"SMALL\", \"MEDIUM\" , \"FULL\"\n",
    "\n",
    "if VARIANT == \"SMALL\":\n",
    "    df = pd.read_pickle(\"../Data/df.pkl\")\n",
    "    df = df.head(20)\n",
    "elif VARIANT == \"MEDIUM\":\n",
    "    df = pd.read_pickle(\"../Data/df.pkl\")\n",
    "    df = df.head(500)\n",
    "else:\n",
    "    df = pd.read_pickle(\"../Data/df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5MNMH621JB0GF09H0000000</td>\n",
       "      <td>Angst vor dem «harten Brexit» auf der Insel - ...</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Wenn Großbritannien Ende März den Ausstieg aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SM3THB1DXFJ50MP0000000</td>\n",
       "      <td>Fleischindustrie wehrt sich gegen Marketing fü...</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Fleisch aus dem Labor ist noch eine Zukunftsvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5SM3THB1DXFJ50MY0000000</td>\n",
       "      <td>Der AP-Überblick am Nachmittag</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die AP Weltnachrichten haben heute unter ander...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5STNVWH1DXFJ53VM0000000</td>\n",
       "      <td>Laborfleisch soll in drei Jahren auf die Telle...</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Maastricht (AP) - Das niederländische Unterneh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VHK2XG1JB0GF4Y50000000</td>\n",
       "      <td>Israelische Forscher wollen künstliche Steaks ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die Weltbevölkerung wächst, die Nachfrage nach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>67KW1VK1F15WB4660000000</td>\n",
       "      <td>Kein Titel</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>6 Am anfang drei Fragen 1. Können wir andere m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>67KW1VK1F15WB46B0000000</td>\n",
       "      <td>Leben und schmecken lassen</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Ein saftiges Filet, für das kein Huhn sterben ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>7W29GN20YC2460S30000000</td>\n",
       "      <td>ABSCHIED VOM ALTEN ITALIEN</td>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>John Dickie: »Delizia! Die Italiener und  ihre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>7X8DW4712SK2G0H10000000</td>\n",
       "      <td>Essen aus dem Labor</td>\n",
       "      <td>2009-12-08</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Es ist der letzte Tag auf der Lebensmittelmess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>7Y5T7F412SK2G46M0000000</td>\n",
       "      <td>15 Ideen, die unser Leben verändern ZEIT</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>2010</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Der frühere IBM-Chef Thomas Watson ist heute b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4858 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "0     5MNMH621JB0GF09H0000000  \\\n",
       "1     5SM3THB1DXFJ50MP0000000   \n",
       "2     5SM3THB1DXFJ50MY0000000   \n",
       "3     5STNVWH1DXFJ53VM0000000   \n",
       "4     5VHK2XG1JB0GF4Y50000000   \n",
       "...                       ...   \n",
       "4853  67KW1VK1F15WB4660000000   \n",
       "4854  67KW1VK1F15WB46B0000000   \n",
       "4855  7W29GN20YC2460S30000000   \n",
       "4856  7X8DW4712SK2G0H10000000   \n",
       "4857  7Y5T7F412SK2G46M0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "0     Angst vor dem «harten Brexit» auf der Insel - ...       2017-01-15  \\\n",
       "1     Fleischindustrie wehrt sich gegen Marketing fü...       2018-06-21   \n",
       "2                        Der AP-Überblick am Nachmittag       2018-06-21   \n",
       "3     Laborfleisch soll in drei Jahren auf die Telle...       2018-07-17   \n",
       "4     Israelische Forscher wollen künstliche Steaks ...       2019-02-26   \n",
       "...                                                 ...              ...   \n",
       "4853                                         Kein Titel       2023-02-21   \n",
       "4854                         Leben und schmecken lassen       2023-02-21   \n",
       "4855                         ABSCHIED VOM ALTEN ITALIEN       2009-05-13   \n",
       "4856                                Essen aus dem Labor       2009-12-08   \n",
       "4857           15 Ideen, die unser Leben verändern ZEIT       2010-04-06   \n",
       "\n",
       "      publication_year    publisher   \n",
       "0                 2017   AP Deutsch  \\\n",
       "1                 2018   AP Deutsch   \n",
       "2                 2018   AP Deutsch   \n",
       "3                 2018   AP Deutsch   \n",
       "4                 2019   AP Deutsch   \n",
       "...                ...          ...   \n",
       "4853              2023  ZEIT Wissen   \n",
       "4854              2023  ZEIT Wissen   \n",
       "4855              2009  ZEIT Wissen   \n",
       "4856              2009  ZEIT Wissen   \n",
       "4857              2010  ZEIT Wissen   \n",
       "\n",
       "                                                   text  \n",
       "0     Wenn Großbritannien Ende März den Ausstieg aus...  \n",
       "1     Fleisch aus dem Labor ist noch eine Zukunftsvi...  \n",
       "2     Die AP Weltnachrichten haben heute unter ander...  \n",
       "3     Maastricht (AP) - Das niederländische Unterneh...  \n",
       "4     Die Weltbevölkerung wächst, die Nachfrage nach...  \n",
       "...                                                 ...  \n",
       "4853  6 Am anfang drei Fragen 1. Können wir andere m...  \n",
       "4854  Ein saftiges Filet, für das kein Huhn sterben ...  \n",
       "4855  John Dickie: »Delizia! Die Italiener und  ihre...  \n",
       "4856  Es ist der letzte Tag auf der Lebensmittelmess...  \n",
       "4857  Der frühere IBM-Chef Thomas Watson ist heute b...  \n",
       "\n",
       "[4858 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the German language model in Spacy\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove double dashes\n",
    "    text = text.replace('--', ' ')\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r\"[^A-Za-z0-9äöüÄÖÜß ]+\", '', text)\n",
    "    \n",
    "    # Lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join([token.lemma_.lower() for token in doc])\n",
    "\n",
    "    # If the first word has the label \"GPE\", remove it\n",
    "    if doc[0].ent_type_ == 'GPE':\n",
    "        print('GPE found')\n",
    "        lemmatized_text = lemmatized_text.split(' ', 1)[1]\n",
    "        \n",
    "    return lemmatized_text\n",
    "\n",
    "# Apply the clean_text function to the 'text' column in df_processed and save as a new dataframe df_clean\n",
    "df_full = df.copy()\n",
    "df_full['clean_text'] = df_full['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word count column to dataframe\n",
    "df_full['word_count'] = 0\n",
    "\n",
    "# Iterate over the dataframe and count the number of words in each text\n",
    "for index in df_full.index:\n",
    "    doc = nlp(df_full['clean_text'][index])\n",
    "    df_full.loc[index, 'word_count'] = len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5MNMH621JB0GF09H0000000</td>\n",
       "      <td>Angst vor dem «harten Brexit» auf der Insel - ...</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Wenn Großbritannien Ende März den Ausstieg aus...</td>\n",
       "      <td>wenn großbritannien ende märz der ausstieg aus...</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SM3THB1DXFJ50MP0000000</td>\n",
       "      <td>Fleischindustrie wehrt sich gegen Marketing fü...</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Fleisch aus dem Labor ist noch eine Zukunftsvi...</td>\n",
       "      <td>fleisch aus der labor sein noch ein zukunftsvi...</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5SM3THB1DXFJ50MY0000000</td>\n",
       "      <td>Der AP-Überblick am Nachmittag</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die AP Weltnachrichten haben heute unter ander...</td>\n",
       "      <td>der ap weltnachrichten haben heute unter ander...</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5STNVWH1DXFJ53VM0000000</td>\n",
       "      <td>Laborfleisch soll in drei Jahren auf die Telle...</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Maastricht (AP) - Das niederländische Unterneh...</td>\n",
       "      <td>maastricht ap   der niederländisch unternehmen...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VHK2XG1JB0GF4Y50000000</td>\n",
       "      <td>Israelische Forscher wollen künstliche Steaks ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die Weltbevölkerung wächst, die Nachfrage nach...</td>\n",
       "      <td>der weltbevölkerung wachsen der nachfrage nach...</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>67KW1VK1F15WB4660000000</td>\n",
       "      <td>Kein Titel</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>6 Am anfang drei Fragen 1. Können wir andere m...</td>\n",
       "      <td>6 an anfang drei frage 1 können wir anderer mi...</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>67KW1VK1F15WB46B0000000</td>\n",
       "      <td>Leben und schmecken lassen</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Ein saftiges Filet, für das kein Huhn sterben ...</td>\n",
       "      <td>ein saftig filet für der kein huhn sterben mus...</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>7W29GN20YC2460S30000000</td>\n",
       "      <td>ABSCHIED VOM ALTEN ITALIEN</td>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>John Dickie: »Delizia! Die Italiener und  ihre...</td>\n",
       "      <td>john dickie delizia der italiener und   ihr kü...</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>7X8DW4712SK2G0H10000000</td>\n",
       "      <td>Essen aus dem Labor</td>\n",
       "      <td>2009-12-08</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Es ist der letzte Tag auf der Lebensmittelmess...</td>\n",
       "      <td>es sein der letzter tag auf der lebensmittelme...</td>\n",
       "      <td>2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>7Y5T7F412SK2G46M0000000</td>\n",
       "      <td>15 Ideen, die unser Leben verändern ZEIT</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>2010</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Der frühere IBM-Chef Thomas Watson ist heute b...</td>\n",
       "      <td>der früh ibmchef thomas watson sein heute berü...</td>\n",
       "      <td>6247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4858 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "0     5MNMH621JB0GF09H0000000  \\\n",
       "1     5SM3THB1DXFJ50MP0000000   \n",
       "2     5SM3THB1DXFJ50MY0000000   \n",
       "3     5STNVWH1DXFJ53VM0000000   \n",
       "4     5VHK2XG1JB0GF4Y50000000   \n",
       "...                       ...   \n",
       "4853  67KW1VK1F15WB4660000000   \n",
       "4854  67KW1VK1F15WB46B0000000   \n",
       "4855  7W29GN20YC2460S30000000   \n",
       "4856  7X8DW4712SK2G0H10000000   \n",
       "4857  7Y5T7F412SK2G46M0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "0     Angst vor dem «harten Brexit» auf der Insel - ...       2017-01-15  \\\n",
       "1     Fleischindustrie wehrt sich gegen Marketing fü...       2018-06-21   \n",
       "2                        Der AP-Überblick am Nachmittag       2018-06-21   \n",
       "3     Laborfleisch soll in drei Jahren auf die Telle...       2018-07-17   \n",
       "4     Israelische Forscher wollen künstliche Steaks ...       2019-02-26   \n",
       "...                                                 ...              ...   \n",
       "4853                                         Kein Titel       2023-02-21   \n",
       "4854                         Leben und schmecken lassen       2023-02-21   \n",
       "4855                         ABSCHIED VOM ALTEN ITALIEN       2009-05-13   \n",
       "4856                                Essen aus dem Labor       2009-12-08   \n",
       "4857           15 Ideen, die unser Leben verändern ZEIT       2010-04-06   \n",
       "\n",
       "      publication_year    publisher   \n",
       "0                 2017   AP Deutsch  \\\n",
       "1                 2018   AP Deutsch   \n",
       "2                 2018   AP Deutsch   \n",
       "3                 2018   AP Deutsch   \n",
       "4                 2019   AP Deutsch   \n",
       "...                ...          ...   \n",
       "4853              2023  ZEIT Wissen   \n",
       "4854              2023  ZEIT Wissen   \n",
       "4855              2009  ZEIT Wissen   \n",
       "4856              2009  ZEIT Wissen   \n",
       "4857              2010  ZEIT Wissen   \n",
       "\n",
       "                                                   text   \n",
       "0     Wenn Großbritannien Ende März den Ausstieg aus...  \\\n",
       "1     Fleisch aus dem Labor ist noch eine Zukunftsvi...   \n",
       "2     Die AP Weltnachrichten haben heute unter ander...   \n",
       "3     Maastricht (AP) - Das niederländische Unterneh...   \n",
       "4     Die Weltbevölkerung wächst, die Nachfrage nach...   \n",
       "...                                                 ...   \n",
       "4853  6 Am anfang drei Fragen 1. Können wir andere m...   \n",
       "4854  Ein saftiges Filet, für das kein Huhn sterben ...   \n",
       "4855  John Dickie: »Delizia! Die Italiener und  ihre...   \n",
       "4856  Es ist der letzte Tag auf der Lebensmittelmess...   \n",
       "4857  Der frühere IBM-Chef Thomas Watson ist heute b...   \n",
       "\n",
       "                                             clean_text  word_count  \n",
       "0     wenn großbritannien ende märz der ausstieg aus...         763  \n",
       "1     fleisch aus der labor sein noch ein zukunftsvi...         708  \n",
       "2     der ap weltnachrichten haben heute unter ander...         632  \n",
       "3     maastricht ap   der niederländisch unternehmen...         225  \n",
       "4     der weltbevölkerung wachsen der nachfrage nach...         631  \n",
       "...                                                 ...         ...  \n",
       "4853  6 an anfang drei frage 1 können wir anderer mi...         305  \n",
       "4854  ein saftig filet für der kein huhn sterben mus...         266  \n",
       "4855  john dickie delizia der italiener und   ihr kü...         912  \n",
       "4856  es sein der letzter tag auf der lebensmittelme...        2548  \n",
       "4857  der früh ibmchef thomas watson sein heute berü...        6247  \n",
       "\n",
       "[4858 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_pickle(\"../Data/df_full.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANT = \"LARGE\" # \"SMALL\", \"MEDIUM\" , \"FULL\"\n",
    "\n",
    "if VARIANT == \"SMALL\":\n",
    "    df = pd.read_pickle(\"../Data/df_full.pkl\")\n",
    "    df = df.head(20)\n",
    "elif VARIANT == \"MEDIUM\":\n",
    "    df = pd.read_pickle(\"../Data/df_full.pkl\")\n",
    "    df = df.head(500)\n",
    "else:\n",
    "    df = pd.read_pickle(\"../Data/df_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only the columns 'nexis_id', 'title', 'publication_date',  'publisher', 'text', 'clean_text'\n",
    "df = df[['nexis_id', 'title', 'publication_date', 'publication_year', 'publisher', 'text', 'clean_text']]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df.to_csv('../Data/df.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from before 2004\n",
    "df_pre2004 = df[df['publication_year'] < 2004]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_pre2004.to_csv('../Data/df_pre2004.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from 2004\n",
    "df_2004 = df[df['publication_year'] == 2004]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_2004.to_csv('../Data/df_2004.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from after 2004\n",
    "df_post2004 = df[df['publication_year'] > 2004]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_post2004.to_csv('../Data/df_post2004.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from before 2009\n",
    "df_first_half = df[df['publication_year'] < 2009]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_first_half.to_csv('../Data/df_pre2009.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from after 2009\n",
    "df_second_half = df[df['publication_year'] >= 2009]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_second_half.to_csv('../Data/df_post2009.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
