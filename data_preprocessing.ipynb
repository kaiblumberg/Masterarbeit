{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the dataframe from the raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import spacy\n",
    "import re\n",
    "from lingua import Language, LanguageDetectorBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    global empty_counter\n",
    "\n",
    "    # Load the XML file\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Define the namespace\n",
    "    namespace = {\n",
    "        'atom': 'http://www.w3.org/2005/Atom',\n",
    "        'nitf': 'http://iptc.org/std/NITF/2006-10-18/',\n",
    "        'dc': 'http://purl.org/dc/elements/1.1/'\n",
    "    }\n",
    "\n",
    "    # Extract the ID\n",
    "    nexis_id = root.find('.//atom:id', namespace).text\n",
    "    nexis_id = nexis_id.split('Item:')[1]\n",
    "    nexis_id = nexis_id.replace(\"-\", \"\")\n",
    "\n",
    "    # Extract the title\n",
    "    title = root.find('.//atom:title', namespace).text\n",
    "\n",
    "    # Extract the published date\n",
    "    published_date = root.find('.//atom:published', namespace).text\n",
    "    published_date = published_date.split('T')[0]\n",
    "\n",
    "    # Extract the publisher\n",
    "    publisher = root.find('.//metadata/publicationInfo/publicationName').text\n",
    "\n",
    "\n",
    "    # Extract the body text\n",
    "    body_text = root.find('.//nitf:body.content//bodyText//p', namespace)\n",
    "\n",
    "    # Extract all body paragraphs and join them into a single line\n",
    "    body_paragraphs = []\n",
    "    body_text_element = root.find('.//nitf:body.content//bodyText', namespace)\n",
    "    if body_text_element is not None:\n",
    "        for p_element in body_text_element.findall('.//p', namespace):\n",
    "            if p_element.text:\n",
    "                body_paragraphs.append(p_element.text.strip())\n",
    "    text = ' '.join(body_paragraphs)\n",
    "\n",
    "    # Check for empty text bodies and return\n",
    "    if text == '':\n",
    "        #print('No text body in file ' + file_path)\n",
    "        empty_counter += 1\n",
    "        return\n",
    "\n",
    "    # Create a dictionary with the extracted values\n",
    "    data_dict = {\n",
    "        'nexis_id': [nexis_id],\n",
    "        'title': [title],\n",
    "        'publication_date': [published_date],\n",
    "        'publisher': [publisher],\n",
    "        'text': [text]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles removed: 90\n",
      "Number of articles accepted: 6779\n"
     ]
    }
   ],
   "source": [
    "# Root Directory of the data\n",
    "folder_path = 'c:\\\\Friendcloud\\\\_University\\\\_Masterarbeit\\\\Data\\\\Nexis\\\\'\n",
    "\n",
    "# Initialize empty counter\n",
    "empty_counter = 0\n",
    "\n",
    "# Go through all subdirectories and fill raw_data with the data\n",
    "raw_data = []\n",
    "for root, _, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.xml'):\n",
    "            try:\n",
    "                file_path = os.path.join(root, file)\n",
    "                data = parse_xml(file_path)\n",
    "                raw_data.append(data)\n",
    "            except:\n",
    "                print('Error in file ' + file_path)\n",
    "\n",
    "# Build pandas DataFrame\n",
    "df_raw = pd.concat(raw_data, ignore_index=True)\n",
    "print('Number of articles removed: ' + str(empty_counter))\n",
    "print('Number of articles accepted: ' + str(len(df_raw.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5MNMH621JB0GF09H0000000</td>\n",
       "      <td>Angst vor dem «harten Brexit» auf der Insel - ...</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Wenn Großbritannien Ende März den Ausstieg aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SM3THB1DXFJ50MP0000000</td>\n",
       "      <td>Fleischindustrie wehrt sich gegen Marketing fü...</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Fleisch aus dem Labor ist noch eine Zukunftsvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5SM3THB1DXFJ50MY0000000</td>\n",
       "      <td>Der AP-Überblick am Nachmittag</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die AP Weltnachrichten haben heute unter ander...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5STNVWH1DXFJ53VM0000000</td>\n",
       "      <td>Laborfleisch soll in drei Jahren auf die Telle...</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Maastricht (AP) - Das niederländische Unterneh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VHK2XG1JB0GF4Y50000000</td>\n",
       "      <td>Israelische Forscher wollen künstliche Steaks ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die Weltbevölkerung wächst, die Nachfrage nach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>67KW1VK1F15WB4660000000</td>\n",
       "      <td>Kein Titel</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>6 Am anfang drei Fragen 1. Können wir andere m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>67KW1VK1F15WB46B0000000</td>\n",
       "      <td>Leben und schmecken lassen</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Ein saftiges Filet, für das kein Huhn sterben ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6776</th>\n",
       "      <td>7W29GN20YC2460S30000000</td>\n",
       "      <td>ABSCHIED VOM ALTEN ITALIEN</td>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>John Dickie: »Delizia! Die Italiener und  ihre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>7X8DW4712SK2G0H10000000</td>\n",
       "      <td>Essen aus dem Labor</td>\n",
       "      <td>2009-12-08</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Es ist der letzte Tag auf der Lebensmittelmess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>7Y5T7F412SK2G46M0000000</td>\n",
       "      <td>15 Ideen, die unser Leben verändern ZEIT</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Der frühere IBM-Chef Thomas Watson ist heute b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6779 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "0     5MNMH621JB0GF09H0000000  \\\n",
       "1     5SM3THB1DXFJ50MP0000000   \n",
       "2     5SM3THB1DXFJ50MY0000000   \n",
       "3     5STNVWH1DXFJ53VM0000000   \n",
       "4     5VHK2XG1JB0GF4Y50000000   \n",
       "...                       ...   \n",
       "6774  67KW1VK1F15WB4660000000   \n",
       "6775  67KW1VK1F15WB46B0000000   \n",
       "6776  7W29GN20YC2460S30000000   \n",
       "6777  7X8DW4712SK2G0H10000000   \n",
       "6778  7Y5T7F412SK2G46M0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "0     Angst vor dem «harten Brexit» auf der Insel - ...       2017-01-15  \\\n",
       "1     Fleischindustrie wehrt sich gegen Marketing fü...       2018-06-21   \n",
       "2                        Der AP-Überblick am Nachmittag       2018-06-21   \n",
       "3     Laborfleisch soll in drei Jahren auf die Telle...       2018-07-17   \n",
       "4     Israelische Forscher wollen künstliche Steaks ...       2019-02-26   \n",
       "...                                                 ...              ...   \n",
       "6774                                         Kein Titel       2023-02-21   \n",
       "6775                         Leben und schmecken lassen       2023-02-21   \n",
       "6776                         ABSCHIED VOM ALTEN ITALIEN       2009-05-13   \n",
       "6777                                Essen aus dem Labor       2009-12-08   \n",
       "6778           15 Ideen, die unser Leben verändern ZEIT       2010-04-06   \n",
       "\n",
       "        publisher                                               text  \n",
       "0      AP Deutsch  Wenn Großbritannien Ende März den Ausstieg aus...  \n",
       "1      AP Deutsch  Fleisch aus dem Labor ist noch eine Zukunftsvi...  \n",
       "2      AP Deutsch  Die AP Weltnachrichten haben heute unter ander...  \n",
       "3      AP Deutsch  Maastricht (AP) - Das niederländische Unterneh...  \n",
       "4      AP Deutsch  Die Weltbevölkerung wächst, die Nachfrage nach...  \n",
       "...           ...                                                ...  \n",
       "6774  ZEIT Wissen  6 Am anfang drei Fragen 1. Können wir andere m...  \n",
       "6775  ZEIT Wissen  Ein saftiges Filet, für das kein Huhn sterben ...  \n",
       "6776  ZEIT Wissen  John Dickie: »Delizia! Die Italiener und  ihre...  \n",
       "6777  ZEIT Wissen  Es ist der letzte Tag auf der Lebensmittelmess...  \n",
       "6778  ZEIT Wissen  Der frühere IBM-Chef Thomas Watson ist heute b...  \n",
       "\n",
       "[6779 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_pickle(\"../Data/df_raw.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5MNMH621JB0GF09H0000000</td>\n",
       "      <td>Angst vor dem «harten Brexit» auf der Insel - ...</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Wenn Großbritannien Ende März den Ausstieg aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SM3THB1DXFJ50MP0000000</td>\n",
       "      <td>Fleischindustrie wehrt sich gegen Marketing fü...</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Fleisch aus dem Labor ist noch eine Zukunftsvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5SM3THB1DXFJ50MY0000000</td>\n",
       "      <td>Der AP-Überblick am Nachmittag</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die AP Weltnachrichten haben heute unter ander...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5STNVWH1DXFJ53VM0000000</td>\n",
       "      <td>Laborfleisch soll in drei Jahren auf die Telle...</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Maastricht (AP) - Das niederländische Unterneh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VHK2XG1JB0GF4Y50000000</td>\n",
       "      <td>Israelische Forscher wollen künstliche Steaks ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die Weltbevölkerung wächst, die Nachfrage nach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>67KW1VK1F15WB4660000000</td>\n",
       "      <td>Kein Titel</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>6 Am anfang drei Fragen 1. Können wir andere m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>67KW1VK1F15WB46B0000000</td>\n",
       "      <td>Leben und schmecken lassen</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Ein saftiges Filet, für das kein Huhn sterben ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6776</th>\n",
       "      <td>7W29GN20YC2460S30000000</td>\n",
       "      <td>ABSCHIED VOM ALTEN ITALIEN</td>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>John Dickie: »Delizia! Die Italiener und  ihre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>7X8DW4712SK2G0H10000000</td>\n",
       "      <td>Essen aus dem Labor</td>\n",
       "      <td>2009-12-08</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Es ist der letzte Tag auf der Lebensmittelmess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>7Y5T7F412SK2G46M0000000</td>\n",
       "      <td>15 Ideen, die unser Leben verändern ZEIT</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Der frühere IBM-Chef Thomas Watson ist heute b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6779 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "0     5MNMH621JB0GF09H0000000  \\\n",
       "1     5SM3THB1DXFJ50MP0000000   \n",
       "2     5SM3THB1DXFJ50MY0000000   \n",
       "3     5STNVWH1DXFJ53VM0000000   \n",
       "4     5VHK2XG1JB0GF4Y50000000   \n",
       "...                       ...   \n",
       "6774  67KW1VK1F15WB4660000000   \n",
       "6775  67KW1VK1F15WB46B0000000   \n",
       "6776  7W29GN20YC2460S30000000   \n",
       "6777  7X8DW4712SK2G0H10000000   \n",
       "6778  7Y5T7F412SK2G46M0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "0     Angst vor dem «harten Brexit» auf der Insel - ...       2017-01-15  \\\n",
       "1     Fleischindustrie wehrt sich gegen Marketing fü...       2018-06-21   \n",
       "2                        Der AP-Überblick am Nachmittag       2018-06-21   \n",
       "3     Laborfleisch soll in drei Jahren auf die Telle...       2018-07-17   \n",
       "4     Israelische Forscher wollen künstliche Steaks ...       2019-02-26   \n",
       "...                                                 ...              ...   \n",
       "6774                                         Kein Titel       2023-02-21   \n",
       "6775                         Leben und schmecken lassen       2023-02-21   \n",
       "6776                         ABSCHIED VOM ALTEN ITALIEN       2009-05-13   \n",
       "6777                                Essen aus dem Labor       2009-12-08   \n",
       "6778           15 Ideen, die unser Leben verändern ZEIT       2010-04-06   \n",
       "\n",
       "        publisher                                               text  \n",
       "0      AP Deutsch  Wenn Großbritannien Ende März den Ausstieg aus...  \n",
       "1      AP Deutsch  Fleisch aus dem Labor ist noch eine Zukunftsvi...  \n",
       "2      AP Deutsch  Die AP Weltnachrichten haben heute unter ander...  \n",
       "3      AP Deutsch  Maastricht (AP) - Das niederländische Unterneh...  \n",
       "4      AP Deutsch  Die Weltbevölkerung wächst, die Nachfrage nach...  \n",
       "...           ...                                                ...  \n",
       "6774  ZEIT Wissen  6 Am anfang drei Fragen 1. Können wir andere m...  \n",
       "6775  ZEIT Wissen  Ein saftiges Filet, für das kein Huhn sterben ...  \n",
       "6776  ZEIT Wissen  John Dickie: »Delizia! Die Italiener und  ihre...  \n",
       "6777  ZEIT Wissen  Es ist der letzte Tag auf der Lebensmittelmess...  \n",
       "6778  ZEIT Wissen  Der frühere IBM-Chef Thomas Watson ist heute b...  \n",
       "\n",
       "[6779 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed = pd.read_pickle(\"../Data/df_raw.pkl\")\n",
    "\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year of publication to dataset\n",
    "df_processed['publication_date'] = pd.to_datetime(df_processed['publication_date'], errors='coerce')\n",
    "df_processed['publication_year'] = df_processed['publication_date'].dt.year\n",
    "df_processed = df_processed[['nexis_id', 'title', 'publication_date', 'publication_year', 'publisher', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles removed: 3\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with duplicate id\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed.drop_duplicates(subset='nexis_id', keep='first')\n",
    "count_after = len(df_processed.index)\n",
    "print('Number of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>609WC4P1JBN9716M0000000</td>\n",
       "      <td>Olivenöl und Reis würden zuerst ausgehen</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>2020</td>\n",
       "      <td>Wiler Zeitung</td>\n",
       "      <td>Bis vor kurzem war das Szenario in der Schweiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>7T50VNF12SGXD0820000000</td>\n",
       "      <td>Nummer sicher</td>\n",
       "      <td>2008-01-26</td>\n",
       "      <td>2008</td>\n",
       "      <td>Main-Taunus-Kurier (Germany)</td>\n",
       "      <td>Der Bundestag gibt grünes Licht für das neue G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>42KBNX2000SV03YR0000000</td>\n",
       "      <td>None</td>\n",
       "      <td>2001-03-12</td>\n",
       "      <td>2001</td>\n",
       "      <td>Der Spiegel</td>\n",
       "      <td>An ein Steak oder eine Roulade traut sich auch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>5KR4P0M1DYHXW30J0000000</td>\n",
       "      <td>\"Die Bayer-Monsanto-Fusion ist beunruhigend\"</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bergische Morgenpost</td>\n",
       "      <td>Johannes Remmel Der NRW-Umweltminister sieht R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>5SF7YFP1F16T21FB0000000</td>\n",
       "      <td>Einen sauberen Burger, bitte!</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>2018</td>\n",
       "      <td>St.Galler Tagblatt (Stammausgabe)</td>\n",
       "      <td>Lebensmittel  Fleischkonsum ohne schlechtes Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>64HSNP51JBK924760000000</td>\n",
       "      <td>Hersteller von Fleischersatz faszinieren Anleg...</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>2022</td>\n",
       "      <td>Börse online</td>\n",
       "      <td>Pflanzen-Burger statt Weihnachtsgans, Pilz-Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>65T6DDY1DY4BY14H0000000</td>\n",
       "      <td>Bühler spannt mit mehreren Unternehmen zusammen</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>2022</td>\n",
       "      <td>Wiler Zeitung</td>\n",
       "      <td>Thomas Griesser Kym Fleischersatz  Beim Techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>57F2G9B1JCN5V4K50000000</td>\n",
       "      <td>WISSENSCHAFT &amp; TECHNIK</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>2013</td>\n",
       "      <td>NZZ Folio</td>\n",
       "      <td>Erst käme der Blitz, dann der Knall. Häuser un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>5X509TF1F13R82VP0000000</td>\n",
       "      <td>Käfer &amp; Co. als Leckerbissen</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>2019</td>\n",
       "      <td>Ried Echo</td>\n",
       "      <td>Hmmm, lecker sieht der Burger aus! So richtig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>62YYVY51F13R80MY0000000</td>\n",
       "      <td>Eine Frage des Vertrauens Kruschel erklärt´s :...</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>2021</td>\n",
       "      <td>Lampertheimer Zeitung (Germany)</td>\n",
       "      <td>Vor 20 Jahren wurde es eingeführt und dürfte j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "6707  609WC4P1JBN9716M0000000  \\\n",
       "3657  7T50VNF12SGXD0820000000   \n",
       "1022  42KBNX2000SV03YR0000000   \n",
       "416   5KR4P0M1DYHXW30J0000000   \n",
       "4936  5SF7YFP1F16T21FB0000000   \n",
       "844   64HSNP51JBK924760000000   \n",
       "6719  65T6DDY1DY4BY14H0000000   \n",
       "4115  57F2G9B1JCN5V4K50000000   \n",
       "4662  5X509TF1F13R82VP0000000   \n",
       "2967  62YYVY51F13R80MY0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "6707           Olivenöl und Reis würden zuerst ausgehen       2020-07-10  \\\n",
       "3657                                      Nummer sicher       2008-01-26   \n",
       "1022                                               None       2001-03-12   \n",
       "416        \"Die Bayer-Monsanto-Fusion ist beunruhigend\"       2016-09-17   \n",
       "4936                      Einen sauberen Burger, bitte!       2018-05-30   \n",
       "844   Hersteller von Fleischersatz faszinieren Anleg...       2022-01-13   \n",
       "6719    Bühler spannt mit mehreren Unternehmen zusammen       2022-06-29   \n",
       "4115                             WISSENSCHAFT & TECHNIK       2013-01-07   \n",
       "4662                       Käfer & Co. als Leckerbissen       2019-09-28   \n",
       "2967  Eine Frage des Vertrauens Kruschel erklärt´s :...       2021-06-22   \n",
       "\n",
       "      publication_year                          publisher   \n",
       "6707              2020                      Wiler Zeitung  \\\n",
       "3657              2008       Main-Taunus-Kurier (Germany)   \n",
       "1022              2001                        Der Spiegel   \n",
       "416               2016               Bergische Morgenpost   \n",
       "4936              2018  St.Galler Tagblatt (Stammausgabe)   \n",
       "844               2022                       Börse online   \n",
       "6719              2022                      Wiler Zeitung   \n",
       "4115              2013                          NZZ Folio   \n",
       "4662              2019                          Ried Echo   \n",
       "2967              2021    Lampertheimer Zeitung (Germany)   \n",
       "\n",
       "                                                   text  \n",
       "6707  Bis vor kurzem war das Szenario in der Schweiz...  \n",
       "3657  Der Bundestag gibt grünes Licht für das neue G...  \n",
       "1022  An ein Steak oder eine Roulade traut sich auch...  \n",
       "416   Johannes Remmel Der NRW-Umweltminister sieht R...  \n",
       "4936  Lebensmittel  Fleischkonsum ohne schlechtes Ge...  \n",
       "844   Pflanzen-Burger statt Weihnachtsgans, Pilz-Ste...  \n",
       "6719  Thomas Griesser Kym Fleischersatz  Beim Techno...  \n",
       "4115  Erst käme der Blitz, dann der Knall. Häuser un...  \n",
       "4662  Hmmm, lecker sieht der Burger aus! So richtig ...  \n",
       "2967  Vor 20 Jahren wurde es eingeführt und dürfte j...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find examples of articles with duplicate text\n",
    "df_processed[df_processed.duplicated(subset='text', keep=False)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles removed: 1278\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with duplicate text\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed.drop_duplicates(subset='text', keep='first')\n",
    "count_after = len(df_processed.index)\n",
    "print('Number of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles removed: 73\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with length less than 100 characters\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['text'].str.len() > 100]\n",
    "count_after = len(df_processed.index)\n",
    "print('Number of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "EN    118\n",
      "ES      1\n",
      "Name: count, dtype: int64\n",
      "publisher\n",
      "dpa-AFX ProFeed                                                              19\n",
      "News Bites - People in Business                                              12\n",
      "American Banking and Market News                                             10\n",
      "Spiegel Online                                                                7\n",
      "Industry SnapShot                                                             4\n",
      "GJAE - German Journal of Agricultural Economics (ehemals Agrarwirtschaft)     4\n",
      "Agrarwirtschaft                                                               4\n",
      "Newstex Blogs                                                                 4\n",
      "Industry SnapShot Summary                                                     3\n",
      "PR Newswire                                                                   2\n",
      "MENAFN - Market Reports (English)                                             2\n",
      "MENAFN - Press Releases (English)                                             2\n",
      "Dorset Echo                                                                   1\n",
      "The Sunday Times (London)                                                     1\n",
      "TVEyes - BBC 1 Yorkshire and Lincolnshire                                     1\n",
      "TVEyes - BBC 1 South East                                                     1\n",
      "TVEyes - BBC 1 Southampton                                                    1\n",
      "TVEyes - BBC 1 North West                                                     1\n",
      "TVEyes - BBC 1 Wales                                                          1\n",
      "TVEyes - BBC 1 Scotland                                                       1\n",
      "The Philadelphia Daily News                                                   1\n",
      "Medical Buyer                                                                 1\n",
      "Seeking Alpha - Earnings Call Transcripts                                     1\n",
      "Oxford Mail                                                                   1\n",
      "TVEyes - BBC 1 East Midlands                                                  1\n",
      "The Philadelphia Inquirer                                                     1\n",
      "Die Welt                                                                      1\n",
      "dailyrecord.co.uk                                                             1\n",
      "Brisbane Times                                                                1\n",
      "just-food global news                                                         1\n",
      "Process                                                                       1\n",
      "Bournemouth Echo                                                              1\n",
      "SPIEGEL ONLINE                                                                1\n",
      "TVEyes - BBC 1 East                                                           1\n",
      "TVEyes - BBC 1 Northern Ireland                                               1\n",
      "Xinhua General News Service                                                   1\n",
      "FD (Fair Disclosure) Wire                                                     1\n",
      "The Times of Israel                                                           1\n",
      "FoodNavigator-Asia.com                                                        1\n",
      "UNI (United News of India)                                                    1\n",
      "The Guardian (London)                                                         1\n",
      "TVEyes - BBC Radio 4                                                          1\n",
      "The Northern Echo (Newsquest Regional Press)                                  1\n",
      "thetimes.co.uk                                                                1\n",
      "Hispanic PR Wire English                                                      1\n",
      "Global Data Point                                                             1\n",
      "Communications Earth & Environment                                            1\n",
      "Targeted News Service                                                         1\n",
      "Market News Publishing                                                        1\n",
      "Sydney Morning Herald (Australia)                                             1\n",
      "The Shelby Report                                                             1\n",
      "PR Newswire Asia                                                              1\n",
      "Business Monitor Online                                                       1\n",
      "Hispanic PR Wire Spanish                                                      1\n",
      "manchestereveningnews.co.uk                                                   1\n",
      "WELT ONLINE (Deutsch)                                                         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of articles removed: 119\n"
     ]
    }
   ],
   "source": [
    "# Remove articles which are not in German using lingua\n",
    "detector = LanguageDetectorBuilder.from_all_spoken_languages().build()\n",
    "\n",
    "# Add empty language column to dataset\n",
    "df_processed['language'] = ''\n",
    "\n",
    "# Detect language of each article\n",
    "for index, row in df_processed.iterrows():\n",
    "    text = row['text']\n",
    "    language = detector.detect_language_of(text)\n",
    "    df_processed.at[index, 'language'] = language.iso_code_639_1.name\n",
    "\n",
    "# Print the language and publisher of articles which are not in German\n",
    "print(df_processed[df_processed['language'] != 'DE']['language'].value_counts())\n",
    "print(df_processed[df_processed['language'] != 'DE']['publisher'].value_counts())\n",
    "\n",
    "# Remove articles which are not in German\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['language'] == 'DE']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of articles removed: 4\n",
      "\n",
      "Number of articles removed: 1\n",
      "\n",
      "Number of articles removed: 2\n",
      "\n",
      "Number of articles removed: 3\n",
      "\n",
      "Number of articles removed: 10\n",
      "\n",
      "Number of articles removed: 2\n",
      "\n",
      "Number of articles removed: 6\n",
      "\n",
      "Number of articles removed: 30\n",
      "\n",
      "Number of articles removed: 1\n",
      "\n",
      "Number of articles removed: 1\n",
      "\n",
      "Number of articles removed: 9\n",
      "\n",
      "Number of articles removed: 625\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with title 'Programmübersicht'\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['title'] != 'Programmübersicht']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with title 'Programmübersicht Samstag'\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['title'] != 'Programmübersicht Samstag']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with title 'Programmhinweise'\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['title'] != 'Programmhinweise']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with specific nexis_ids (tv program)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4SC3XK90TXHH10SS0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4SC3XKC0TXHH101J0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4SC3XKJ0TXHH101K0000000']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with specific nexis_ids (theatre)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4JXWDKF0TWRXK1R10000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '3SGDYHS0006XC4P80000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '5KNN3CD1JC3P04FD0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4KF5FDD0TWRXK1WY0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '585XW971JBPW93GX0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4S4Y46D0TWX2707B0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '554MD281F19FX2YB0000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '4S554KS0TWX271450000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '518R7XC1F19FX3P10000000']\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '539ND9G1DYK6Y0950000000']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove all articles that have the word \"Dissertationen\" in the title (list of dissertations, not an article)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[~df_processed['title'].str.contains('Dissertationen', na=False)]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove all articles that have the word \"Börsentag\" in the title (not an article)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[~df_processed['title'].str.contains('Börsentag', na=False)]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove all articles that have the word \"Börsen-Ticker\" in the title (not an article)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[~df_processed['title'].str.contains('Börsen-Ticker', na=False)]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with specific nexis_ids (no article)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '65S924K1JBR841DW0000000']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with specific nexis_ids (hidden duplicate)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['nexis_id'] != '64HSHSG1F15WB1NC0000000']\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles with publication_year before 1994 (too little data)\n",
    "count_before = len(df_processed.index)\n",
    "df_processed = df_processed[df_processed['publication_year'] >= 1994]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# Remove articles from the last 4 months before the last article published (includes web-crawled data)\n",
    "count_before = len(df_processed.index)\n",
    "# Find the last article published\n",
    "last_article = df_processed['publication_date'].max()\n",
    "# Remove articles from the last 4 months before the last article published\n",
    "df_processed = df_processed[df_processed['publication_date'] < last_article - pd.DateOffset(months=4)]\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the dataframe\n",
    "df_processed = df_processed.reset_index(drop=True)\n",
    "\n",
    "# Remove the language column\n",
    "df_processed = df_processed.drop(columns=['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of articles removed: 226\n"
     ]
    }
   ],
   "source": [
    "count_before = len(df_processed.index)\n",
    "drop_ids = []\n",
    "\n",
    "# Remove all articles that have the same first 100 characters (hidden duplicates)\n",
    "for i in range(len(df_processed)):\n",
    "    for j in range(i+1, len(df_processed)):\n",
    "        text1 = df_processed['text'][i]\n",
    "        text2 = df_processed['text'][j]\n",
    "        if len(text1) >= 100 and len(text2) >= 100:\n",
    "            if text1[:100] == text2[:100]:\n",
    "                # Check whether the articles have the same nexis_id\n",
    "                if df_processed['nexis_id'][i] != df_processed['nexis_id'][j]:\n",
    "                    # Remove the shorter article\n",
    "                    if len(text1) <= len(text2):\n",
    "                        drop_ids.append(df_processed['nexis_id'][i])\n",
    "                    else:\n",
    "                        drop_ids.append(df_processed['nexis_id'][j])\n",
    "\n",
    "# Remove articles with nexis_ids in drop_ids\n",
    "for nexis_id in drop_ids:\n",
    "    df_processed = df_processed[df_processed['nexis_id'] != nexis_id]\n",
    "\n",
    "count_after = len(df_processed.index)\n",
    "print('\\nNumber of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# reindex dataframe\n",
    "df_processed.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5MNMH621JB0GF09H0000000</td>\n",
       "      <td>Angst vor dem «harten Brexit» auf der Insel - ...</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Wenn Großbritannien Ende März den Ausstieg aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SM3THB1DXFJ50MP0000000</td>\n",
       "      <td>Fleischindustrie wehrt sich gegen Marketing fü...</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Fleisch aus dem Labor ist noch eine Zukunftsvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5SM3THB1DXFJ50MY0000000</td>\n",
       "      <td>Der AP-Überblick am Nachmittag</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die AP Weltnachrichten haben heute unter ander...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5STNVWH1DXFJ53VM0000000</td>\n",
       "      <td>Laborfleisch soll in drei Jahren auf die Telle...</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Maastricht (AP) - Das niederländische Unterneh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VHK2XG1JB0GF4Y50000000</td>\n",
       "      <td>Israelische Forscher wollen künstliche Steaks ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die Weltbevölkerung wächst, die Nachfrage nach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>67KW1VK1F15WB4660000000</td>\n",
       "      <td>Kein Titel</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>6 Am anfang drei Fragen 1. Können wir andere m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>67KW1VK1F15WB46B0000000</td>\n",
       "      <td>Leben und schmecken lassen</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Ein saftiges Filet, für das kein Huhn sterben ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>7W29GN20YC2460S30000000</td>\n",
       "      <td>ABSCHIED VOM ALTEN ITALIEN</td>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>John Dickie: »Delizia! Die Italiener und  ihre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>7X8DW4712SK2G0H10000000</td>\n",
       "      <td>Essen aus dem Labor</td>\n",
       "      <td>2009-12-08</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Es ist der letzte Tag auf der Lebensmittelmess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>7Y5T7F412SK2G46M0000000</td>\n",
       "      <td>15 Ideen, die unser Leben verändern ZEIT</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>2010</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Der frühere IBM-Chef Thomas Watson ist heute b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4386 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "0     5MNMH621JB0GF09H0000000  \\\n",
       "1     5SM3THB1DXFJ50MP0000000   \n",
       "2     5SM3THB1DXFJ50MY0000000   \n",
       "3     5STNVWH1DXFJ53VM0000000   \n",
       "4     5VHK2XG1JB0GF4Y50000000   \n",
       "...                       ...   \n",
       "4381  67KW1VK1F15WB4660000000   \n",
       "4382  67KW1VK1F15WB46B0000000   \n",
       "4383  7W29GN20YC2460S30000000   \n",
       "4384  7X8DW4712SK2G0H10000000   \n",
       "4385  7Y5T7F412SK2G46M0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "0     Angst vor dem «harten Brexit» auf der Insel - ...       2017-01-15  \\\n",
       "1     Fleischindustrie wehrt sich gegen Marketing fü...       2018-06-21   \n",
       "2                        Der AP-Überblick am Nachmittag       2018-06-21   \n",
       "3     Laborfleisch soll in drei Jahren auf die Telle...       2018-07-17   \n",
       "4     Israelische Forscher wollen künstliche Steaks ...       2019-02-26   \n",
       "...                                                 ...              ...   \n",
       "4381                                         Kein Titel       2023-02-21   \n",
       "4382                         Leben und schmecken lassen       2023-02-21   \n",
       "4383                         ABSCHIED VOM ALTEN ITALIEN       2009-05-13   \n",
       "4384                                Essen aus dem Labor       2009-12-08   \n",
       "4385           15 Ideen, die unser Leben verändern ZEIT       2010-04-06   \n",
       "\n",
       "      publication_year    publisher   \n",
       "0                 2017   AP Deutsch  \\\n",
       "1                 2018   AP Deutsch   \n",
       "2                 2018   AP Deutsch   \n",
       "3                 2018   AP Deutsch   \n",
       "4                 2019   AP Deutsch   \n",
       "...                ...          ...   \n",
       "4381              2023  ZEIT Wissen   \n",
       "4382              2023  ZEIT Wissen   \n",
       "4383              2009  ZEIT Wissen   \n",
       "4384              2009  ZEIT Wissen   \n",
       "4385              2010  ZEIT Wissen   \n",
       "\n",
       "                                                   text  \n",
       "0     Wenn Großbritannien Ende März den Ausstieg aus...  \n",
       "1     Fleisch aus dem Labor ist noch eine Zukunftsvi...  \n",
       "2     Die AP Weltnachrichten haben heute unter ander...  \n",
       "3     Maastricht (AP) - Das niederländische Unterneh...  \n",
       "4     Die Weltbevölkerung wächst, die Nachfrage nach...  \n",
       "...                                                 ...  \n",
       "4381  6 Am anfang drei Fragen 1. Können wir andere m...  \n",
       "4382  Ein saftiges Filet, für das kein Huhn sterben ...  \n",
       "4383  John Dickie: »Delizia! Die Italiener und  ihre...  \n",
       "4384  Es ist der letzte Tag auf der Lebensmittelmess...  \n",
       "4385  Der frühere IBM-Chef Thomas Watson ist heute b...  \n",
       "\n",
       "[4386 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_pickle(\"../Data/df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANT = \"LARGE\" # \"SMALL\", \"MEDIUM\" , \"FULL\"\n",
    "\n",
    "if VARIANT == \"SMALL\":\n",
    "    df = pd.read_pickle(\"../Data/df.pkl\")\n",
    "    df = df.head(20)\n",
    "elif VARIANT == \"MEDIUM\":\n",
    "    df = pd.read_pickle(\"../Data/df.pkl\")\n",
    "    df = df.head(500)\n",
    "else:\n",
    "    df = pd.read_pickle(\"../Data/df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5MNMH621JB0GF09H0000000</td>\n",
       "      <td>Angst vor dem «harten Brexit» auf der Insel - ...</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Wenn Großbritannien Ende März den Ausstieg aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SM3THB1DXFJ50MP0000000</td>\n",
       "      <td>Fleischindustrie wehrt sich gegen Marketing fü...</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Fleisch aus dem Labor ist noch eine Zukunftsvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5SM3THB1DXFJ50MY0000000</td>\n",
       "      <td>Der AP-Überblick am Nachmittag</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die AP Weltnachrichten haben heute unter ander...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5STNVWH1DXFJ53VM0000000</td>\n",
       "      <td>Laborfleisch soll in drei Jahren auf die Telle...</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Maastricht (AP) - Das niederländische Unterneh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VHK2XG1JB0GF4Y50000000</td>\n",
       "      <td>Israelische Forscher wollen künstliche Steaks ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die Weltbevölkerung wächst, die Nachfrage nach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>67KW1VK1F15WB4660000000</td>\n",
       "      <td>Kein Titel</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>6 Am anfang drei Fragen 1. Können wir andere m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>67KW1VK1F15WB46B0000000</td>\n",
       "      <td>Leben und schmecken lassen</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Ein saftiges Filet, für das kein Huhn sterben ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>7W29GN20YC2460S30000000</td>\n",
       "      <td>ABSCHIED VOM ALTEN ITALIEN</td>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>John Dickie: »Delizia! Die Italiener und  ihre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>7X8DW4712SK2G0H10000000</td>\n",
       "      <td>Essen aus dem Labor</td>\n",
       "      <td>2009-12-08</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Es ist der letzte Tag auf der Lebensmittelmess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>7Y5T7F412SK2G46M0000000</td>\n",
       "      <td>15 Ideen, die unser Leben verändern ZEIT</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>2010</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Der frühere IBM-Chef Thomas Watson ist heute b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4386 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "0     5MNMH621JB0GF09H0000000  \\\n",
       "1     5SM3THB1DXFJ50MP0000000   \n",
       "2     5SM3THB1DXFJ50MY0000000   \n",
       "3     5STNVWH1DXFJ53VM0000000   \n",
       "4     5VHK2XG1JB0GF4Y50000000   \n",
       "...                       ...   \n",
       "4381  67KW1VK1F15WB4660000000   \n",
       "4382  67KW1VK1F15WB46B0000000   \n",
       "4383  7W29GN20YC2460S30000000   \n",
       "4384  7X8DW4712SK2G0H10000000   \n",
       "4385  7Y5T7F412SK2G46M0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "0     Angst vor dem «harten Brexit» auf der Insel - ...       2017-01-15  \\\n",
       "1     Fleischindustrie wehrt sich gegen Marketing fü...       2018-06-21   \n",
       "2                        Der AP-Überblick am Nachmittag       2018-06-21   \n",
       "3     Laborfleisch soll in drei Jahren auf die Telle...       2018-07-17   \n",
       "4     Israelische Forscher wollen künstliche Steaks ...       2019-02-26   \n",
       "...                                                 ...              ...   \n",
       "4381                                         Kein Titel       2023-02-21   \n",
       "4382                         Leben und schmecken lassen       2023-02-21   \n",
       "4383                         ABSCHIED VOM ALTEN ITALIEN       2009-05-13   \n",
       "4384                                Essen aus dem Labor       2009-12-08   \n",
       "4385           15 Ideen, die unser Leben verändern ZEIT       2010-04-06   \n",
       "\n",
       "      publication_year    publisher   \n",
       "0                 2017   AP Deutsch  \\\n",
       "1                 2018   AP Deutsch   \n",
       "2                 2018   AP Deutsch   \n",
       "3                 2018   AP Deutsch   \n",
       "4                 2019   AP Deutsch   \n",
       "...                ...          ...   \n",
       "4381              2023  ZEIT Wissen   \n",
       "4382              2023  ZEIT Wissen   \n",
       "4383              2009  ZEIT Wissen   \n",
       "4384              2009  ZEIT Wissen   \n",
       "4385              2010  ZEIT Wissen   \n",
       "\n",
       "                                                   text  \n",
       "0     Wenn Großbritannien Ende März den Ausstieg aus...  \n",
       "1     Fleisch aus dem Labor ist noch eine Zukunftsvi...  \n",
       "2     Die AP Weltnachrichten haben heute unter ander...  \n",
       "3     Maastricht (AP) - Das niederländische Unterneh...  \n",
       "4     Die Weltbevölkerung wächst, die Nachfrage nach...  \n",
       "...                                                 ...  \n",
       "4381  6 Am anfang drei Fragen 1. Können wir andere m...  \n",
       "4382  Ein saftiges Filet, für das kein Huhn sterben ...  \n",
       "4383  John Dickie: »Delizia! Die Italiener und  ihre...  \n",
       "4384  Es ist der letzte Tag auf der Lebensmittelmess...  \n",
       "4385  Der frühere IBM-Chef Thomas Watson ist heute b...  \n",
       "\n",
       "[4386 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the German language model in Spacy\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove special characters\n",
    "    text = re.sub(\"[^A-Za-zäöüÄÖÜß ]+\", ' ', text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join([token.lemma_.lower() if token.lemma_ != '--' else token.text.lower() for token in doc])   \n",
    "\n",
    "    # If the first word has the label \"GPE\", remove it\n",
    "    if doc[0].ent_type_ == 'GPE':\n",
    "        print('GPE found')\n",
    "        lemmatized_text = lemmatized_text.split(' ', 1)[1]\n",
    "        \n",
    "    return lemmatized_text\n",
    "\n",
    "# Apply the clean_text function to the 'text' column in df_processed and save as a new dataframe df_clean\n",
    "df_full = df.copy()\n",
    "df_full['clean_text'] = df_full['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles removed: 21\n"
     ]
    }
   ],
   "source": [
    "# Remove articles with duplicate clean_text\n",
    "count_before = len(df_full.index)\n",
    "df_full = df_full.drop_duplicates(subset='clean_text', keep='first')\n",
    "count_after = len(df_full.index)\n",
    "print('Number of articles removed: ' + str(count_before - count_after))\n",
    "\n",
    "# reindex dataframe\n",
    "df_full.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word count column to dataframe\n",
    "df_full['word_count'] = 0\n",
    "\n",
    "# Iterate over the dataframe and count the number of words in each text\n",
    "for index in df_full.index:\n",
    "    doc = nlp(df_full['clean_text'][index])\n",
    "    df_full.loc[index, 'word_count'] = len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nexis_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5MNMH621JB0GF09H0000000</td>\n",
       "      <td>Angst vor dem «harten Brexit» auf der Insel - ...</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Wenn Großbritannien Ende März den Ausstieg aus...</td>\n",
       "      <td>wenn großbritannien ende märz der ausstieg aus...</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SM3THB1DXFJ50MP0000000</td>\n",
       "      <td>Fleischindustrie wehrt sich gegen Marketing fü...</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Fleisch aus dem Labor ist noch eine Zukunftsvi...</td>\n",
       "      <td>fleisch aus der labor sein noch ein zukunftsvi...</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5SM3THB1DXFJ50MY0000000</td>\n",
       "      <td>Der AP-Überblick am Nachmittag</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die AP Weltnachrichten haben heute unter ander...</td>\n",
       "      <td>der ap weltnachrichten haben heute unter ander...</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5STNVWH1DXFJ53VM0000000</td>\n",
       "      <td>Laborfleisch soll in drei Jahren auf die Telle...</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Maastricht (AP) - Das niederländische Unterneh...</td>\n",
       "      <td>maastricht ap der niederländisch unternehmen m...</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VHK2XG1JB0GF4Y50000000</td>\n",
       "      <td>Israelische Forscher wollen künstliche Steaks ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019</td>\n",
       "      <td>AP Deutsch</td>\n",
       "      <td>Die Weltbevölkerung wächst, die Nachfrage nach...</td>\n",
       "      <td>der weltbevölkerung wachsen der nachfrage nach...</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360</th>\n",
       "      <td>67KW1VK1F15WB4660000000</td>\n",
       "      <td>Kein Titel</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>6 Am anfang drei Fragen 1. Können wir andere m...</td>\n",
       "      <td>an anfang drei frage können wir anderer mit ge...</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4361</th>\n",
       "      <td>67KW1VK1F15WB46B0000000</td>\n",
       "      <td>Leben und schmecken lassen</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Ein saftiges Filet, für das kein Huhn sterben ...</td>\n",
       "      <td>ein saftig filet für der kein huhn sterben mus...</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>7W29GN20YC2460S30000000</td>\n",
       "      <td>ABSCHIED VOM ALTEN ITALIEN</td>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>John Dickie: »Delizia! Die Italiener und  ihre...</td>\n",
       "      <td>john dickie delizia der italiener und ihr küch...</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>7X8DW4712SK2G0H10000000</td>\n",
       "      <td>Essen aus dem Labor</td>\n",
       "      <td>2009-12-08</td>\n",
       "      <td>2009</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Es ist der letzte Tag auf der Lebensmittelmess...</td>\n",
       "      <td>es sein der letzter tag auf der lebensmittelme...</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>7Y5T7F412SK2G46M0000000</td>\n",
       "      <td>15 Ideen, die unser Leben verändern ZEIT</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>2010</td>\n",
       "      <td>ZEIT Wissen</td>\n",
       "      <td>Der frühere IBM-Chef Thomas Watson ist heute b...</td>\n",
       "      <td>der früh ibm chef thomas watson sein heute ber...</td>\n",
       "      <td>6162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4365 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nexis_id   \n",
       "0     5MNMH621JB0GF09H0000000  \\\n",
       "1     5SM3THB1DXFJ50MP0000000   \n",
       "2     5SM3THB1DXFJ50MY0000000   \n",
       "3     5STNVWH1DXFJ53VM0000000   \n",
       "4     5VHK2XG1JB0GF4Y50000000   \n",
       "...                       ...   \n",
       "4360  67KW1VK1F15WB4660000000   \n",
       "4361  67KW1VK1F15WB46B0000000   \n",
       "4362  7W29GN20YC2460S30000000   \n",
       "4363  7X8DW4712SK2G0H10000000   \n",
       "4364  7Y5T7F412SK2G46M0000000   \n",
       "\n",
       "                                                  title publication_date   \n",
       "0     Angst vor dem «harten Brexit» auf der Insel - ...       2017-01-15  \\\n",
       "1     Fleischindustrie wehrt sich gegen Marketing fü...       2018-06-21   \n",
       "2                        Der AP-Überblick am Nachmittag       2018-06-21   \n",
       "3     Laborfleisch soll in drei Jahren auf die Telle...       2018-07-17   \n",
       "4     Israelische Forscher wollen künstliche Steaks ...       2019-02-26   \n",
       "...                                                 ...              ...   \n",
       "4360                                         Kein Titel       2023-02-21   \n",
       "4361                         Leben und schmecken lassen       2023-02-21   \n",
       "4362                         ABSCHIED VOM ALTEN ITALIEN       2009-05-13   \n",
       "4363                                Essen aus dem Labor       2009-12-08   \n",
       "4364           15 Ideen, die unser Leben verändern ZEIT       2010-04-06   \n",
       "\n",
       "      publication_year    publisher   \n",
       "0                 2017   AP Deutsch  \\\n",
       "1                 2018   AP Deutsch   \n",
       "2                 2018   AP Deutsch   \n",
       "3                 2018   AP Deutsch   \n",
       "4                 2019   AP Deutsch   \n",
       "...                ...          ...   \n",
       "4360              2023  ZEIT Wissen   \n",
       "4361              2023  ZEIT Wissen   \n",
       "4362              2009  ZEIT Wissen   \n",
       "4363              2009  ZEIT Wissen   \n",
       "4364              2010  ZEIT Wissen   \n",
       "\n",
       "                                                   text   \n",
       "0     Wenn Großbritannien Ende März den Ausstieg aus...  \\\n",
       "1     Fleisch aus dem Labor ist noch eine Zukunftsvi...   \n",
       "2     Die AP Weltnachrichten haben heute unter ander...   \n",
       "3     Maastricht (AP) - Das niederländische Unterneh...   \n",
       "4     Die Weltbevölkerung wächst, die Nachfrage nach...   \n",
       "...                                                 ...   \n",
       "4360  6 Am anfang drei Fragen 1. Können wir andere m...   \n",
       "4361  Ein saftiges Filet, für das kein Huhn sterben ...   \n",
       "4362  John Dickie: »Delizia! Die Italiener und  ihre...   \n",
       "4363  Es ist der letzte Tag auf der Lebensmittelmess...   \n",
       "4364  Der frühere IBM-Chef Thomas Watson ist heute b...   \n",
       "\n",
       "                                             clean_text  word_count  \n",
       "0     wenn großbritannien ende märz der ausstieg aus...         777  \n",
       "1     fleisch aus der labor sein noch ein zukunftsvi...         718  \n",
       "2     der ap weltnachrichten haben heute unter ander...         618  \n",
       "3     maastricht ap der niederländisch unternehmen m...         224  \n",
       "4     der weltbevölkerung wachsen der nachfrage nach...         638  \n",
       "...                                                 ...         ...  \n",
       "4360  an anfang drei frage können wir anderer mit ge...         276  \n",
       "4361  ein saftig filet für der kein huhn sterben mus...         266  \n",
       "4362  john dickie delizia der italiener und ihr küch...         840  \n",
       "4363  es sein der letzter tag auf der lebensmittelme...        2544  \n",
       "4364  der früh ibm chef thomas watson sein heute ber...        6162  \n",
       "\n",
       "[4365 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_pickle(\"../Data/df_full.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANT = \"LARGE\" # \"SMALL\", \"MEDIUM\" , \"FULL\"\n",
    "\n",
    "if VARIANT == \"SMALL\":\n",
    "    df = pd.read_pickle(\"../Data/df_full.pkl\")\n",
    "    df = df.head(20)\n",
    "elif VARIANT == \"MEDIUM\":\n",
    "    df = pd.read_pickle(\"../Data/df_full.pkl\")\n",
    "    df = df.head(500)\n",
    "else:\n",
    "    df = pd.read_pickle(\"../Data/df_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only the columns 'nexis_id', 'title', 'publication_date',  'publisher', 'text', 'clean_text'\n",
    "df = df[['nexis_id', 'title', 'publication_date', 'publication_year', 'publisher', 'text', 'clean_text']]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df.to_csv('../Data/df.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from before 2004\n",
    "df_pre2004 = df[df['publication_year'] < 2004]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_pre2004.to_csv('../Data/df_pre2004.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from 2004\n",
    "df_2004 = df[df['publication_year'] == 2004]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_2004.to_csv('../Data/df_2004.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from after 2004\n",
    "df_post2004 = df[df['publication_year'] > 2004]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_post2004.to_csv('../Data/df_post2004.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from before 2009\n",
    "df_first_half = df[df['publication_year'] < 2009]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_first_half.to_csv('../Data/df_first_half.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from after 2009\n",
    "df_second_half = df[df['publication_year'] >= 2009]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_second_half.to_csv('../Data/df_second_half.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from the year 2020 (COVID)\n",
    "df_2020 = df[df['publication_year'] == 2020]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_2020.to_csv('../Data/df_2020.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from after the year 2020 including 2020 (COVID)\n",
    "df_post2020 = df[df['publication_year'] >= 2020]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_post2020.to_csv('../Data/df_post2020.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from the year 2001 (Meat)\n",
    "df_2001 = df[df['publication_year'] == 2001]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_2001.to_csv('../Data/df_2001.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from the year 2009 (Climate)\n",
    "df_2009 = df[df['publication_year'] == 2009]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_2009.to_csv('../Data/df_2009.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from the year 2013 (Climate)\n",
    "df_2013 = df[df['publication_year'] == 2013]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_2013.to_csv('../Data/df_2013.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only publications from the year 2019 (Climate)\n",
    "df_2019 = df[df['publication_year'] == 2019]\n",
    "\n",
    "# Export the dataframe to a csv file while fixing the encoding for german characters and using tab as a separator\n",
    "df_2019.to_csv('../Data/df_2019.csv', sep='\\t', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
